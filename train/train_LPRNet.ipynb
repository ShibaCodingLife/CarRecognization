{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 定义加载数据的工具"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from data.ccpd2lpr import licenseDataset\n",
    "from torch.utils.data import DataLoader\n",
    "pathToCCPD=r'C:\\CCPD\\CCPD'\n",
    "trainDataSet=licenseDataset(pathToCCPD,['train'],False)\n",
    "valDataSet=licenseDataset(pathToCCPD,['val'],False)\n",
    "\n",
    "trainDataLoader=DataLoader(dataset=trainDataSet,batch_size=32,shuffle=True,num_workers=16)\n",
    "valDataLoader=DataLoader(dataset=valDataSet,batch_size=32,num_workers=16,drop_last=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 加载LPRNet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from LPRNet.LPRNet import LPRNet\n",
    "pretainModelPath=r\"./weights/LPRNet/myLPRNet.pt\"\n",
    "lprnet=LPRNet(lpr_max_len=8,class_num=68,dropout_rate=0.5)\n",
    "lprnet.load_state_dict(torch.load(pretainModelPath))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch.nn\n",
    "import torch\n",
    "from data.ccpd2lpr import CHARS\n",
    "lr=0.001\n",
    "optmizer=torch.optim.RMSprop(lprnet.parameters(),lr)\n",
    "criterion=torch.nn.CTCLoss(blank=len(CHARS)-1, reduction='mean')\n",
    "device=torch.device((\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "total_epoch=100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# # 测试模型的运行并绘制模型结构\n",
    "# import onnx\n",
    "# import torch.onnx\n",
    "# lprnet.to(device) # module类的to是in place操作\n",
    "# inputs=torch.randn(1,3,24,94,dtype=torch.float32).to(device) # tensor类的to不是in place操作\n",
    "# output=lprnet(inputs)\n",
    "# output=output.transpose(0, 2)\n",
    "# output=output.transpose(1, 2)\n",
    "# print(output.shape)\n",
    "# torch.onnx.export(lprnet, inputs, r\"./models/showLPRNet.onnx\", verbose=True, input_names=[\"input\"], output_names=[\"output\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 判断是否是最优模型\n",
    "def isbest(acc_list):\n",
    "    lastest_acc=acc_list[-1]\n",
    "    if lastest_acc==max(acc_list):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 定义学习率调度器\n",
    "def create_lr_scheduler(optimizer,num_step:int,epochs:int,warmup=True,warmup_epochs=10,warmup_factor=1e-3):\n",
    "    assert num_step>0 and epochs>0\n",
    "    if warmup is False:\n",
    "        warmup_epochs=0\n",
    "    def f(x):\n",
    "        if warmup is True and x<=(warmup_epochs*num_step):\n",
    "            alpha=float(x)/(warmup_epochs*num_step)\n",
    "            return warmup_factor*(1-alpha)+alpha\n",
    "        else:\n",
    "            return (1-(x-warmup_epochs*num_step)/((epochs-warmup_epochs)*num_step))**0.9\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer,f)\n",
    "lr_scheduler=create_lr_scheduler(optmizer,len(trainDataLoader),total_epoch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 训练模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "lprnet.to(device)\n",
    "running_losses=[]\n",
    "running_acces=[]\n",
    "\n",
    "\n",
    "def Greedy_Decode_Eval(Net):\n",
    "    Net = Net.eval()\n",
    "    Tp = 0\n",
    "    Tn_1 = 0\n",
    "    Tn_2 = 0\n",
    "    for images, labels, lengths ,_ in valDataLoader:\n",
    "        images=images.to(device)\n",
    "        labels=labels.numpy()\n",
    "        lengths=lengths.numpy()\n",
    "        targets=[]\n",
    "        for i in range(len(labels)):\n",
    "            target=labels[i]\n",
    "            target=target[:lengths[i]:]\n",
    "            targets.append(target)\n",
    "        # forward\n",
    "        # images: [bs, 3, 24, 94]\n",
    "        # prebs:  [bs, 68, 18]\n",
    "        prebs = Net(images)\n",
    "        # greedy decode\n",
    "        prebs = prebs.cpu().detach().numpy()\n",
    "        preb_labels = list()\n",
    "        for i in range(prebs.shape[0]):\n",
    "            preb = prebs[i, :, :]  # 对每张图片 [68, 18]\n",
    "            preb_label = list()\n",
    "            for j in range(preb.shape[1]):  # 18  返回序列中每个位置最大的概率对应的字符idx  其中'-'是67\n",
    "                preb_label.append(np.argmax(preb[:, j], axis=0))\n",
    "\n",
    "            no_repeat_blank_label = list()\n",
    "            pre_c = preb_label[0]\n",
    "            if pre_c != len(CHARS) - 1:  # 记录重复字符\n",
    "                no_repeat_blank_label.append(pre_c)\n",
    "            for c in preb_label:  # 去除重复字符和空白字符'-'\n",
    "                if (pre_c == c) or (c == len(CHARS) - 1):\n",
    "                    if c == len(CHARS) - 1:\n",
    "                        pre_c = c\n",
    "                    continue\n",
    "                no_repeat_blank_label.append(c)\n",
    "                pre_c = c\n",
    "            preb_labels.append(no_repeat_blank_label)  # 得到最终的无重复字符和无空白字符的序列\n",
    "\n",
    "        for i, label in enumerate(preb_labels):  # 统计准确率\n",
    "            if len(label) != len(targets[i]):\n",
    "                Tn_1 += 1  # 错误+1\n",
    "                continue\n",
    "            if (np.asarray(targets[i]) == np.asarray(label)).all():\n",
    "                Tp += 1  # 完全正确+1\n",
    "            else:\n",
    "                Tn_2 += 1\n",
    "    Acc = Tp * 1.0 / (Tp + Tn_1 + Tn_2)\n",
    "    print(\"[Info] Test Accuracy: {} [{}:{}:{}:{}]\".format(Acc, Tp, Tn_1, Tn_2, (Tp+Tn_1+Tn_2)))\n",
    "    return Acc\n",
    "\n",
    "def trainLPRNet(lprnet):\n",
    "    for epoch in tqdm(range(total_epoch), desc='Training model', ncols=100):\n",
    "            lprnet.train()\n",
    "            running_loss=0.0\n",
    "            for images,labels,labelLengths,_ in trainDataLoader:\n",
    "                images,labels,labelLengths=images.to(device),labels.to(device),labelLengths.to(device)\n",
    "                optmizer.zero_grad()\n",
    "                outputs=lprnet(images) # batchsize*68*18\n",
    "                outputs=outputs.transpose(0, 2)\n",
    "                outputs=outputs.transpose(1, 2) # 18,batchsize,68\n",
    "                outputs=F.log_softmax(outputs,dim=2)\n",
    "                output_lengths=torch.full((len(labelLengths),),18)\n",
    "                loss=criterion(outputs,labels,output_lengths,labelLengths)\n",
    "                running_loss+=loss\n",
    "                loss.backward()\n",
    "                optmizer.step()\n",
    "                lr_scheduler.step()\n",
    "            running_loss/=trainDataLoader.batch_size\n",
    "            running_losses.append(running_loss)\n",
    "            acc=Greedy_Decode_Eval(lprnet)\n",
    "            print(f\"epoch: {epoch} loss {running_loss}\")\n",
    "            running_acces.append(acc)\n",
    "            if isbest(running_acces):\n",
    "                torch.save(lprnet.state_dict(),'./mybestLPRNet.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   2%|▉                                            | 1/50 [04:15<3:28:36, 255.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Test Accuracy: 0.0 [0:100991:1:100992]\n",
      "epoch: 0 loss 0.7365410923957825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x000001C8BA6B3700>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\miniconda\\envs\\cv_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"D:\\miniconda\\envs\\cv_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1442, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"D:\\miniconda\\envs\\cv_env\\lib\\multiprocessing\\process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"D:\\miniconda\\envs\\cv_env\\lib\\multiprocessing\\popen_spawn_win32.py\", line 108, in wait\n",
      "    res = _winapi.WaitForSingleObject(int(self._handle), msecs)\n",
      "KeyboardInterrupt: \n",
      "Training model:   2%|▉                                            | 1/50 [06:06<4:59:32, 366.79s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrainLPRNet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlprnet\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[5], line 75\u001B[0m, in \u001B[0;36mtrainLPRNet\u001B[1;34m(lprnet)\u001B[0m\n\u001B[0;32m     73\u001B[0m running_loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0\u001B[39m\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m images,labels,labelLengths,_ \u001B[38;5;129;01min\u001B[39;00m trainDataLoader:\n\u001B[1;32m---> 75\u001B[0m     images,labels,labelLengths\u001B[38;5;241m=\u001B[39m\u001B[43mimages\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m,labels\u001B[38;5;241m.\u001B[39mto(device),labelLengths\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     76\u001B[0m     optmizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     77\u001B[0m     outputs\u001B[38;5;241m=\u001B[39mlprnet(images) \u001B[38;5;66;03m# batchsize*68*18\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "trainLPRNet(lprnet)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Test Accuracy: 0.0 [0:100987:5:100992]\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.0"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Greedy_Decode_Eval(lprnet)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "torch.save(lprnet.state_dict(),'./mylastLPRNet.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lprnet=lprnet.load_state_dict(torch.load())"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
